{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3789c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abbf3f3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4adac9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data size: (41408, 3)\n",
      "                                                text          sentiment  \\\n",
      "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
      "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
      "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
      "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
      "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
      "\n",
      "                                          text_clean  \n",
      "0             word katandandre food crapilicious mkr  \n",
      "1  aussietv white mkr theblock imacelebrityau tod...  \n",
      "2                    classy whore red velvet cupcake  \n",
      "3  meh thanks head concerned another angry dude t...  \n",
      "4  isi account pretending kurdish account like is...  \n",
      "Unique sentiment values before mapping: ['not_cyberbullying' 'gender' 'religion' 'other_cyberbullying' 'age'\n",
      " 'ethnicity']\n",
      "NaN values found after mapping. Check mapping keys and sentiment column values.\n",
      "                                                    text sentiment  \\\n",
      "26172  Here at home. Neighbors pick on my family and ...       age   \n",
      "26173  Being bullied at school: High-achieving boys u...       age   \n",
      "26174  There was a girl in my class in 6th grade who ...       age   \n",
      "26175  He’s probably a white gay kid from some suburb...       age   \n",
      "26176  You are pushed ti resorting. Treating thr bull...       age   \n",
      "...                                                  ...       ...   \n",
      "33985  This girl really tried to say I bullied her in...       age   \n",
      "33986  a bully at school who has been messing with me...       age   \n",
      "33987  I remember I wrote an entire song in 6th grade...       age   \n",
      "33988  I was not the Prom Queen. I was the bullied gi...       age   \n",
      "33989  Everyone tryin to be a “cute alt girl” like th...       age   \n",
      "\n",
      "                                              text_clean  label  \n",
      "26172  home neighbor pick family mind son autistic fe...    NaN  \n",
      "26173  bullied school highachieving boy use strategy ...    NaN  \n",
      "26174  girl class th grade little autistic parent tho...    NaN  \n",
      "26175  probably white gay kid suburb want shoot schoo...    NaN  \n",
      "26176  pushed ti resorting treating thr bully percent...    NaN  \n",
      "...                                                  ...    ...  \n",
      "33985  girl really tried say bullied high school real...    NaN  \n",
      "33986             bully school messing since rd grade lt    NaN  \n",
      "33987  remember wrote entire song th grade called bow...    NaN  \n",
      "33988  prom queen bullied girl black sheep different ...    NaN  \n",
      "33989  everyone tryin cute alt girl like bully middle...    NaN  \n",
      "\n",
      "[7818 rows x 4 columns]\n",
      "Data size after dropping NaNs: (33590, 4)\n",
      "Data is ready for further processing.\n",
      "Distribution of labels: 2    22611\n",
      "0     6068\n",
      "1     4911\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = 'cleaned_cyberbullying_tweets.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "if 'sentiment' not in df.columns or 'text_clean' not in df.columns:\n",
    "    raise ValueError(\"Required columns are missing from the DataFrame.\")\n",
    "\n",
    "print(\"Initial data size:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "#Prompt\n",
    "def add_prompt_to_text(text):\n",
    "    return f\"Please classify the label of this text as either 0, 1, or 2. 0 represents the sentiment 'not_cyberbullying', 1 represents the sentiment 'other_cyberbullying', 2 represents the sentiments ethnicity, religion, gender, or other. 0 is negative, 1 is neutral, and 2 is positive for cyberbullying: {text}\"\n",
    "\n",
    "# Apply the prompt to each text entry in the DataFrame\n",
    "df['text_clean'] = df['text_clean'].apply(add_prompt_to_text)\n",
    "\n",
    "\n",
    "print(\"Unique sentiment values before mapping:\", df['sentiment'].unique())\n",
    "\n",
    "# Mapping sentiments to labels\n",
    "sentiment_mapping = {\n",
    "    'not_cyberbullying': 0,  # Negative\n",
    "    'other_cyberbullying': 1,      # Neutral\n",
    "    'ethnicity': 2,          # Positive\n",
    "    'religion': 2,           # Positive\n",
    "    'gender': 2,             # Positive\n",
    "    'other': 2               # Positive\n",
    "}\n",
    "\n",
    "df['label'] = df['sentiment'].map(sentiment_mapping)\n",
    "\n",
    "if df['label'].isna().any():\n",
    "    print(\"NaN values found after mapping. Check mapping keys and sentiment column values.\")\n",
    "    print(df[df['label'].isna()])\n",
    "else:\n",
    "    print(\"No NaN values after mapping.\")\n",
    "\n",
    "df = df.dropna(subset=['label'])\n",
    "print(\"Data size after dropping NaNs:\", df.shape)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty after dropping NaNs. Adjust data cleaning or check data quality.\")\n",
    "else:\n",
    "    print(\"Data is ready for further processing.\")\n",
    "\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "print(\"Distribution of labels:\", df['label'].value_counts())\n",
    "\n",
    "texts = df['text_clean'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1932be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "train_texts = np.array(train_texts)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "train_labels_series = pd.Series(train_labels)\n",
    "\n",
    "class_counts = train_labels_series.value_counts()\n",
    "max_samples = class_counts.max()\n",
    "\n",
    "sampling_strategy_over = {k: max_samples for k in class_counts.index}\n",
    "sampling_strategy_under = {k: max_samples for k in class_counts.index}\n",
    "\n",
    "over = SMOTE(sampling_strategy=sampling_strategy_over)\n",
    "under = RandomUnderSampler(sampling_strategy=sampling_strategy_under)\n",
    "steps = [('over', over), ('under', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# Resample indices instead of texts\n",
    "indices = np.arange(train_texts.shape[0]).reshape(-1, 1)\n",
    "resampled_indices, resampled_labels = pipeline.fit_resample(indices, train_labels_series)\n",
    "\n",
    "train_texts_resampled = train_texts[resampled_indices.flatten()]\n",
    "train_labels_resampled = train_labels[resampled_indices.flatten()]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "def tokenize_data(texts, tokenizer):\n",
    "    texts = [str(text) for text in texts if text is not None]\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "try:\n",
    "    train_encodings = tokenize_data(train_texts, tokenizer)\n",
    "    val_encodings = tokenize_data(val_texts, tokenizer)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during tokenization: {str(e)}\")\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c979e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of processed item: {'input_ids': tensor([    0, 48759, 13562, 24786, 26293,   784,  1916,  3036, 16490, 44403,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1)}\n",
      "Labels tensor: tensor(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import one_hot\n",
    "from torch import nn\n",
    "\n",
    "class CyberbullyingDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CyberbullyingDataset(train_encodings, train_labels)\n",
    "val_dataset = CyberbullyingDataset(val_encodings, val_labels)\n",
    "\n",
    "test_item = train_dataset[0]\n",
    "print(\"Example of processed item:\", test_item)\n",
    "print(\"Labels tensor:\", test_item['labels'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d19df",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed504686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5670' max='5670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5670/5670 15:11:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.371700</td>\n",
       "      <td>0.445682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.406413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.369864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.263700</td>\n",
       "      <td>0.413479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.409042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5670, training_loss=0.35088898340861, metrics={'train_runtime': 54679.8058, 'train_samples_per_second': 1.659, 'train_steps_per_second': 0.104, 'total_flos': 5965636298501376.0, 'train_loss': 0.35088898340861, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  # Start with 3 epochs\n",
    "    per_device_train_batch_size=16,  # Adjust based on your hardware capability\n",
    "    per_device_eval_batch_size=64,  # Larger batches if your hardware supports it\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,  # Adjust based on the total number of training steps\n",
    "    warmup_steps=500,  # Adjust if needed\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    learning_rate=3e-5  # A typical starting learning rate for fine-tuning\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0706e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3d4ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {'input_ids': batch['input_ids'].to(device),\n",
    "                      'attention_mask': batch['attention_mask'].to(device)}\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.view(-1).cpu().numpy())\n",
    "            true_labels.extend(labels.view(-1).cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4323cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_14492\\1584659242.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: {'accuracy': 0.8493599285501637, 'precision': 0.8482269246189422, 'recall': 0.8493599285501637, 'f1': 0.8472000580954699}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14492\\1159862000.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Metrics:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Metrics:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "val_metrics = evaluate_model(model, val_loader, device)\n",
    "print(\"Validation Metrics:\", val_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
